{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[N-rozměrná koule](https://en.wikipedia.org/wiki/Volume_of_an_n-ball)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Určení obsahu jednotkového kruhu pomocí metody Monte Carlo.\n",
    "\n",
    "Označme $S$ jednotkový kruh a $C$ jemu opsaný čtverec $[-1, 1]\\times[-1, 1]$. \n",
    "Pokud vezmeme náhodný bod uvnitř $C$ (o obsahu $4$), je pravděpodobnost $p$, že bod bude uvnitř kruhu rovna\n",
    "$$ p = \\frac{|S|}{|C|} = \\frac{|S|}{4} $$\n",
    "Metoda Monete Carlo spočívá ve vygenerování velkého množství náhodných bodů a určení podílu těch, padly dovnitř kruhu. V tomto jednoduchém případě víme, že přesná hodnota je $$ p = \\frac{\\pi}{4} $$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_point():\n",
    "    return [random.uniform(-1,1), random.uniform(-1,1)]\n",
    "\n",
    "\n",
    "def is_in_disk(x, y):\n",
    "    return x*x+y*y < 1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "powers = [1, 2, 3, 4, 5, 6, 7]\n",
    "sample_sizes = [10**i for i in powers]\n",
    "\n",
    "def sampling(sample_sizes):\n",
    "    n_samples = 0\n",
    "    n_in = 0\n",
    "    counts = []\n",
    "    for size in sample_sizes:\n",
    "        while n_samples < size:\n",
    "            x, y = get_point()\n",
    "            n_in += is_in_disk(x, y)\n",
    "            n_samples+=1        \n",
    "        counts.append(n_in)\n",
    "    return counts\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling time:  10.827210155985085\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "begin = timer()\n",
    "counts = sampling(sample_sizes)\n",
    "end = timer()\n",
    "print(\"Sampling time: \", end - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zde je vidět poněkud slabý výpočetní výkon Pythonu, na jeden vzorek (sample) potřebujeme řádově 1000 taktů procesoru.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3.2 0.0146018366026 0.273958114476\n",
      "2 3.0 0.0353981633974 2.1001843303\n",
      "3 3.088 0.0133981633974 2.51374925067\n",
      "4 3.1592 0.00440183660255 2.61162370302\n",
      "5 3.14172 3.18366025517e-05 0.0597314970972\n",
      "6 3.14296 0.000341836602552 2.02812747131\n",
      "7 3.1416196 6.73660255168e-06 0.12639142481\n"
     ]
    }
   ],
   "source": [
    "exact_pst = np.pi / 4    \n",
    "sigma = (1 - exact_pst)*exact_pst\n",
    "for power, size, count in zip(powers, sample_sizes, counts):\n",
    "    approx = float(count)/size\n",
    "    error = np.abs(approx - exact_surface)\n",
    "    estim_error = sigma / np.sqrt(size)\n",
    "    print(power, 4*approx, error, error / estim_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S rostoucím počtem vzorků nám klesá chyba, ale velmi pomalu s odmocninou z počtu vzorků, t.j. poslední sloupec je přibližně 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling time:  1.368625033996068\n",
      "3.1419264\n"
     ]
    }
   ],
   "source": [
    "size = 10**7\n",
    "\n",
    "begin = timer()\n",
    "XY = np.random.rand(size, 2)\n",
    "count  = np.sum( np.sum(XY**2, axis = -1) < 1.0 )\n",
    "end = timer()\n",
    "print(\"Sampling time: \", end - begin)\n",
    "print(4*count/size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomocí použití Numpy sice převedeme většinu výpočtu do kompilované knihovny a dosáhneme asi 10x urychlení, \n",
    "ale zase je tento přístup zbytečně náročný na paměť a je limitován pomalým přístupem do paměti. \n",
    "To nyní pomineme a pokusíme se o urychlení pomocí paralelního zpracování.\n",
    "\n",
    "Existují dva koncepty:\n",
    "\n",
    "    1. Spuštění více procesů -- instancí stejného programu. Výhodou je úplné oddělení procesů, \n",
    "    nevýhodou N kopií programu v paměti a složitější komunikace mezi procesy.\n",
    "    \n",
    "    2. Spuštění více vláken (thread) v rámci jednoho programu. Výhodou je rychlejší spouštění vláken, \n",
    "    menší nároky na paměť a snadnější komunikace vláken, nevýhodou je složitější ladění a problémy s \n",
    "    globálními proměnnými. \n",
    "    \n",
    "Efektivní využití dnešního HW vyžaduje použití obou přístupů:\n",
    "    1. Výpočetní cluster je sestaven ze samostatných počítačů, tzv. uzlů. Na každém uzlu běží samostatný proces, \n",
    "    který komunikuje s procesy na jiných uzlech pomocí posílání zpráv (MPI viz. dále).\n",
    "    \n",
    "    2. V rámci jednoho uzlu si proces vytvoří více výpočetních vláken, aby využil všechna jádra uzlu.\n",
    "    \n",
    "    3. Optimalizace. Pro maximální využití výpočetních prostředků se provádějí optimalizace na správné využití cache a \n",
    "    vektorových výpočetních operací."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Interpreter Lock (GIL)\n",
    "\n",
    "Python umí používat vlákna, ale zároveň používá globální zámek, který praktický zajistí, že v každý okamžik aktuálně běží pouze jedno z existujících vláken. Zde se ukazuje, že Python (podobně jako mnoho dalšího SW) nebyl na vícevláknový běh navržen a pro zaručení konzistentního stavu všech interních operací to bylo vyřešeno globálním zámkem. Využití vláken v Pythonu tedy je vhodné pro:\n",
    "- obsluhu asynchonních událostí (komunikace po síti, přerušení)\n",
    "- zefektivnění operací (síť, disk) které neváznou na procesoru\n",
    "\n",
    "Tento koncept se nazývá \"concurency programming\" narozdíl od \"parallel programming\", kde chceme aby více vláken nebo procesů běželo současně. Standardní knihvna pythonu poskytuje dva moduly s podobným rozhraním: modul `threading` pro \n",
    "práci s vlákny synchronyzovanými pomocí GIL a modul `multiprocessing` pro koordinaci více samostatných procesů. Je třeba upozornit, že GIL nevyužívají všechny implementace Pythonu.\n",
    "- CPython - GIL, referenční implementace\n",
    "- PyPy - GIL, just-in-time compiler (cca 5x zrychlení), mírná omezení oproti Pythonu\n",
    "- Jython - no GIL, kompilace do JAVA byte kódu\n",
    "- IronPython - no GIL, založeno na Microsoft .NET platformě\n",
    "\n",
    "Tj. s použitím Jthonu nebo IronPythonu běží vlákna skutečně paralelně."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modul multiprocessing\n",
    "\n",
    "Výpočet vzroků v metodě MC rozdělíme na více procesů, při vytvoření procesu mu předáme funkci kterou má spustit spolu s\n",
    "jejími parametry. Parametry zahrnují i pole `counts` pro uložení výsledků.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10000 7855\n",
      "pi: 3.142\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import queue\n",
    "\n",
    "def sampling(worker_id, size, counts):\n",
    "    XY = np.random.rand(size, 2)\n",
    "    count  = np.sum( np.sum(XY**2, axis = -1) < 1.0 )\n",
    "    counts.put( (size, count) )\n",
    "    print(worker_id, size, count)\n",
    "\n",
    "def process_samples(counts):\n",
    "    total_count = 0\n",
    "    total_samples = 0\n",
    "    while not counts.empty():\n",
    "        n_samples, count = counts.get()\n",
    "        total_samples += n_samples\n",
    "        total_count += count\n",
    "    print(\"pi:\", 4*float(total_count)/total_samples)    \n",
    "    \n",
    "\n",
    "counts = queue.Queue()   \n",
    "sampling(0, 10000, counts)\n",
    "process_samples(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2500000 1962976\n",
      "1 2500000 1962976\n",
      "2 2500000 1962976\n",
      "0 2500000 1962976\n",
      "pi: 3.1407616\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "n_samples = 10**7   \n",
    "n_proc = 4\n",
    "q = multiprocessing.Queue()\n",
    "jobs = []\n",
    "for i in range(n_proc):\n",
    "    n_samples_local = int(n_samples / (n_proc - i))\n",
    "    n_samples -= n_samples_local\n",
    "    p = multiprocessing.Process(target=sampling, args=(i, n_samples_local, q))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "\n",
    "    \n",
    "# Wait for all processes to finish.\n",
    "#q.close()\n",
    "#q.join_thread()\n",
    "for p in jobs:\n",
    "    p.join()\n",
    "    \n",
    "process_samples(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jelikož vytváření procesů je drahé, používá se tzv. Pool. Tedy pevná množina procesů, které se vytvoří jen jednou a pak se jim přiřazuje práce, kterou mají vykonat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
